{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SegmentationModel.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pFTx1ACYmNi5"
      ],
      "authorship_tag": "ABX9TyO5SB5bPh2fI7jdolrGWqzF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lvllvl/unet/blob/master/SegmentationModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58UCK5ZVnuwn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFTx1ACYmNi5",
        "colab_type": "text"
      },
      "source": [
        "## Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE5YrFh_tvqK",
        "colab_type": "text"
      },
      "source": [
        "* imgs/  -- The png image files\n",
        "* masks/ -- PNG segmentation masks (update these!)\n",
        "* segs/  -- The outputs in probability from our * * \n",
        "internal segnet (unreleased, too big)\n",
        "\n",
        "\n",
        "\n",
        "###### Categories \n",
        " * 1 - #402020 - road (all parts, anywhere nobody would look at you funny for driving)\n",
        " * 2 - #ff0000 - lane markings (don't include non lane markings like turn arrows and crosswalks)\n",
        " * 3 - #808060 - undrivable\n",
        " * 4 - #00ff66 - movable (vehicles and people/animals)\n",
        " * 5 - #cc00ff - my car (and anything inside it, including wires, mounts, etc. No reflections)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GXS0VBGnukc",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xJ54484gQEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import pathlib\n",
        "from PIL import  Image\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0SXoe8NsDWO",
        "colab_type": "text"
      },
      "source": [
        "#### Import U-Net repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ybe7KSzgNxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "bae7d424-e5a7-4c42-bca1-c9ca43a39641"
      },
      "source": [
        "! git clone https://github.com/lvllvl/unet.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'unet'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 412 (delta 2), reused 0 (delta 0), pack-reused 406\u001b[K\n",
            "Receiving objects: 100% (412/412), 44.96 MiB | 33.51 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1MMDxAzsAGR",
        "colab_type": "text"
      },
      "source": [
        "#### import comma10k Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pPSTOzlkikQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "06c677ab-2530-4c25-c7f4-bda39d54a378"
      },
      "source": [
        "! git clone https://github.com/commaai/comma10k.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'comma10k'...\n",
            "remote: Enumerating objects: 27383, done.\u001b[K\n",
            "remote: Total 27383 (delta 0), reused 0 (delta 0), pack-reused 27383\u001b[K\n",
            "Receiving objects: 100% (27383/27383), 3.75 GiB | 43.01 MiB/s, done.\n",
            "Resolving deltas: 100% (4283/4283), done.\n",
            "Checking out files: 100% (11203/11203), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5vihNpcsJaW",
        "colab_type": "text"
      },
      "source": [
        "#### Set up the folders, paths "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-f4N_65gbH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = Path.cwd()\n",
        "\n",
        "# Comma10k data\n",
        "comma10kFolder = path/'comma10k'\n",
        "masksFolder = comma10kFolder/'masks' # Images with the masks ( 5574 images )\n",
        "imgsFolder = comma10kFolder/'imgs' # Images with no segmentation\n",
        "\n",
        "# Unet Path \n",
        "unetFolder = path/'unet'\n",
        "\n",
        "\n",
        "# Create directories for Train / validation datasets \n",
        "validFiles = comma10kFolder/'valid'\n",
        "validFiles.mkdir( mode=511, parents= True, exist_ok = False )\n",
        "\n",
        "trainFiles = comma10kFolder/'train'\n",
        "trainFiles.mkdir( mode=511, parents=True, exist_ok=False )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4wcfmCcaw9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "855642f8-9fd9-43ed-e538-cf72b3d73fd9"
      },
      "source": [
        "img = 0\n",
        "for i in imgsFolder.iterdir():\n",
        "  name = i.as_uri()[ 7: ]\n",
        "  print( name )\n",
        "  img = cv2.imread( name )\n",
        "  break \n",
        "img.shape\n",
        "# (874, 1164, 3)\n",
        "# (874, 1164, 3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/comma10k/imgs/0272_55d35794f4955cd1_2018-05-08--18-37-21_13_630.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(874, 1164, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe8gZ8mzn9TD",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nopF6jtoufj",
        "colab_type": "text"
      },
      "source": [
        "#### Rename files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-Aul9z9mc7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "c7ee88d2-7b2a-4569-82d3-00b4b583c508"
      },
      "source": [
        "fileCount = 0\n",
        "prefix = 'mask_'\n",
        "suffix = '.png'\n",
        "\n",
        "for i in masksFolder.iterdir():\n",
        "\n",
        "  file_path = i.as_uri()[ 7:31 ]\n",
        "  \n",
        "  name = i.as_uri()[ 31 : 35 ] \n",
        "\n",
        "  newName = file_path + prefix + name + suffix\n",
        "\n",
        "  i.rename( newName ) # rename the file\n",
        "\n",
        "  # how to evaluate a model in practice \n",
        "  # projects --> github profile, blog, working website \n",
        "  # get good at one specific thing --> e.g., computer vision \n",
        "  \n",
        "  fileCount += 1 \n",
        "\n",
        "  if fileCount % 500 == 0:\n",
        "    print( 'Still processing...file count = ', fileCount )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Still processing...file count =  500\n",
            "Still processing...file count =  1000\n",
            "Still processing...file count =  1500\n",
            "Still processing...file count =  2000\n",
            "Still processing...file count =  2500\n",
            "Still processing...file count =  3000\n",
            "Still processing...file count =  3500\n",
            "Still processing...file count =  4000\n",
            "Still processing...file count =  4500\n",
            "Still processing...file count =  5000\n",
            "Still processing...file count =  5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_PymrffmnFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "4016778e-917e-4c48-b8f2-02f557851de1"
      },
      "source": [
        "fileCount = 0\n",
        "prefix = 'image_'\n",
        "suffix = '.png'\n",
        "\n",
        "\n",
        "for i in imgsFolder.iterdir():\n",
        "  \n",
        "  file_path = i.as_uri()[ 7:30 ]\n",
        "  \n",
        "  name = i.as_uri()[ 30 : 34 ] \n",
        "\n",
        "  newName = file_path + prefix + name + suffix\n",
        "\n",
        "  i.rename( newName ) # rename the file\n",
        "  fileCount += 1 \n",
        "\n",
        "  if fileCount % 500 == 0:\n",
        "    print( 'Still processing...file count = ', fileCount )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Still processing...file count =  500\n",
            "Still processing...file count =  1000\n",
            "Still processing...file count =  1500\n",
            "Still processing...file count =  2000\n",
            "Still processing...file count =  2500\n",
            "Still processing...file count =  3000\n",
            "Still processing...file count =  3500\n",
            "Still processing...file count =  4000\n",
            "Still processing...file count =  4500\n",
            "Still processing...file count =  5000\n",
            "Still processing...file count =  5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljw8UxC96JHj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "014351d2-3cdd-4ab5-c9f6-9448260f597d"
      },
      "source": [
        "for i in comma10kFolder.iterdir():\n",
        "  print( i )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/comma10k/scale\n",
            "/content/comma10k/viewer.py\n",
            "/content/comma10k/imgs\n",
            "/content/comma10k/pencil\n",
            "/content/comma10k/masks\n",
            "/content/comma10k/.git\n",
            "/content/comma10k/.gitignore\n",
            "/content/comma10k/stat.py\n",
            "/content/comma10k/sample.gif\n",
            "/content/comma10k/.github\n",
            "/content/comma10k/README.md\n",
            "/content/comma10k/sample.jpg\n",
            "/content/comma10k/valid\n",
            "/content/comma10k/LICENSE\n",
            "/content/comma10k/train\n",
            "/content/comma10k/tools\n",
            "/content/comma10k/files_trainable\n",
            "/content/comma10k/requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JdHkmSJ8Zq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17a282ee-bbbd-480c-d85f-73afa855dee4"
      },
      "source": [
        "masksFolder.parent"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/comma10k')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZUJhEocEHkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f6df616-58e9-4258-c746-db1fc8664857"
      },
      "source": [
        "mask = 0 \n",
        "img = 0 \n",
        "\n",
        "for i in masksFolder.iterdir():\n",
        "  mask += 1\n",
        "for i in imgsFolder.iterdir():\n",
        "  img += 1\n",
        "\n",
        "print( mask, img )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5574 5574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHtcNBuP2COY",
        "colab_type": "text"
      },
      "source": [
        "#### Split files into train / valid folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wileExm16tkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "69af3eb4-e7ea-4f46-88a6-be2690f7b6ec"
      },
      "source": [
        "# Masked Files -- Change location \n",
        "\n",
        "fileNames = []\n",
        "count = 0\n",
        "\n",
        "for i in masksFolder.iterdir():\n",
        "\n",
        "  fn = i.stem + i.suffix # file name\n",
        "  # print( 'fn = ', fn ) \n",
        "\n",
        "  if count < 4459:  # add to Train folder \n",
        "    fileNum = i.stem[ 5: ]\n",
        "    fileNames.append( fileNum ) # append FileNum to fileNames array \n",
        "    \n",
        "    # Now change the location \n",
        "    i.rename( Path( trainFiles, fn ))\n",
        "\n",
        "  else: # add to Valid folder\n",
        "    i.rename( Path( validFiles, fn ))\n",
        "\n",
        "\n",
        "  count += 1\n",
        "\n",
        "print( 'len of fileNames: ', len( fileNames ))\n",
        "c= 0\n",
        "for i in trainFiles.iterdir():\n",
        "  c += 1\n",
        "print( c )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len of fileNames:  4459\n",
            "4459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuazNEMCBnEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc0e5fcb-1c03-484a-98ae-45ebbb877d79"
      },
      "source": [
        "# Now move the images from the imgsFolder \n",
        "for i in imgsFolder.iterdir():\n",
        "\n",
        "  fn = i.stem + i.suffix # individual file name \n",
        "  \n",
        "  fileNum = i.stem[ 6: ]\n",
        "\n",
        "  if fileNum in fileNames: # change location - train folder if fileNum is in array fileNames\n",
        "    i.rename( Path( trainFiles, fn ))\n",
        "\n",
        "  else: # change location  - valid folder \n",
        "    i.rename( Path( validFiles, fn ))\n",
        "\n",
        "c = 0\n",
        "for i in trainFiles.iterdir():\n",
        "  c += 1 \n",
        "print( c ) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz8Eg-ltjBAb",
        "colab_type": "text"
      },
      "source": [
        "### Data.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUuOjm9c1G81",
        "colab_type": "text"
      },
      "source": [
        "##### Imports, etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGD1vz_v09qG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np \n",
        "import os\n",
        "import glob\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "\n",
        "# CommaAI Labels --> 5 classes\n",
        "road = [ 64,\t32,\t32 ] \n",
        "lane_markings = [ 255, 0, 0 ] \n",
        "undriveable = [ 128, 128, 96 ] \n",
        "movable = [ 0, 255, 102 ] # vehicles, peoples, animals \n",
        "my_vehicle = [ 204,\t0, 255 ]\n",
        "\n",
        "# What does this do?\n",
        "COLOR_DICT = np.array( [ road, lane_markings, undriveable, movable, my_vehicle ])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZYwo7IA1Kgc",
        "colab_type": "text"
      },
      "source": [
        "##### Function: adjustData"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quk4M9O-1P34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjustData( img, mask, flag_multi_class, num_class ):\n",
        "\n",
        "    if( flag_multi_class ):\n",
        "\n",
        "        img = img / 255 \n",
        "        mask = mask[ :,:,:,0 ] if( len( mask.shape ) == 4 ) else mask[ :,:,0 ]\n",
        "        new_mask = np.zeros( mask.shape + ( num_class, ) )\n",
        "\n",
        "        for i in range( num_class ):\n",
        "\n",
        "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
        "            #index = np.where(mask == i)\n",
        "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
        "            #new_mask[index_mask] = 1\n",
        "            new_mask[ mask == i,i ] = 1\n",
        "\n",
        "        new_mask = np.reshape( new_mask,( new_mask.shape[ 0 ],new_mask.shape[ 1 ]*new_mask.shape[ 2 ],new_mask.shape[ 3 ] )) if flag_multi_class else np.reshape( new_mask,( new_mask.shape[ 0 ] * new_mask.shape[ 1 ],new_mask.shape[ 2 ]))\n",
        "        mask = new_mask\n",
        "        \n",
        "        # TODO: delete this \n",
        "        print( 'adjustData: mask.shape --> ' , mask.shape ) \n",
        "\n",
        "    elif ( np.max( img ) > 1 ):\n",
        "\n",
        "        # ???? What does the following do?\n",
        "        img = img / 255\n",
        "        mask = mask / 255\n",
        "        mask[ mask > 0.5 ] = 1\n",
        "        mask[ mask <= 0.5 ] = 0\n",
        "\n",
        "    return ( img,mask )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDP5UPH71U2n",
        "colab_type": "text"
      },
      "source": [
        "##### Function: trainGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvGcSDJ_1cMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainGenerator( batch_size, train_path, image_folder, mask_folder, aug_dict, image_color_mode = \"rgb\",\n",
        "                    mask_color_mode = \"rgb\", image_save_prefix  = \"image\", mask_save_prefix  = \"mask\",\n",
        "                    flag_multi_class = False, num_class = 2, save_to_dir = None, target_size = ( 256,256 ), seed = 1 ):\n",
        "    '''\n",
        "    can generate image and mask at the same time\n",
        "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
        "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "    \n",
        "    # do you want: \n",
        "    - pathlib object?\n",
        "    - string?\n",
        "    Try both /content/comma10k/train\n",
        "    '''\n",
        "    image_datagen = ImageDataGenerator( **aug_dict )\n",
        "\n",
        "    mask_datagen = ImageDataGenerator( **aug_dict )\n",
        "\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [ image_folder ],\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = image_save_prefix,\n",
        "        seed = seed )\n",
        "    \n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [ mask_folder ],\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = mask_save_prefix,\n",
        "        seed = seed )\n",
        "    \n",
        "    train_generator = zip( image_generator, mask_generator )\n",
        "\n",
        "    for ( img,mask ) in train_generator:\n",
        "\n",
        "        img,mask = adjustData( img, mask, flag_multi_class, num_class )\n",
        "        yield ( img,mask )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv-jWANw1hc9",
        "colab_type": "text"
      },
      "source": [
        "##### Function: testGenerator "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1X4RHv31l5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testGenerator( test_path, num_image = 30, target_size = (256,256), flag_multi_class = True, as_gray = False ):\n",
        "  '''\n",
        "      num_image -->> ??? What does this do ? total number of images in your test dataset????\n",
        "      target_size = ( ?, ? ) what should this actually be?\n",
        "  '''\n",
        "  for i in range( num_image ): # do the following for all images in test dataset\n",
        "\n",
        "      img = io.imread( os.path.join( test_path,\"%d.png\"%i ), as_gray = as_gray )\n",
        "\n",
        "      img = img / 255\n",
        "\n",
        "      img = trans.resize( img,target_size )\n",
        "\n",
        "      img = np.reshape( img, img.shape+(1,) ) if ( not flag_multi_class ) else img\n",
        "\n",
        "      img = np.reshape( img, (1,) + img.shape )\n",
        "\n",
        "      yield img"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKzr0DxB10pF",
        "colab_type": "text"
      },
      "source": [
        "##### Function: geneTrainNpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvdfkutq14S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def geneTrainNpy( image_path, mask_path, flag_multi_class = False, num_class = 2,\n",
        "                 image_prefix = \"image\", mask_prefix = \"mask\", image_as_gray = True, mask_as_gray = True ):\n",
        "  '''\n",
        "  image_path -> path to image\n",
        "  mask_path -> path to image\n",
        "\n",
        "  flag_multi_class = T/F --> Are there multiple classes or not?\n",
        "  num_class = # His is set to 2, because it's black & white \n",
        "\n",
        "  image_prefix --> how is filename labeled?\n",
        "  mask_prefix --> how is filename labeled?\n",
        "\n",
        "  image_as_gray --> T / F --> is the image gray or not\n",
        "  mask_as_gray --> T / F --> is MASK gray or not  \n",
        "\n",
        "  '''\n",
        "    # Access image path\n",
        "  image_name_arr = glob.glob( os.path.join( image_path,\"%s*.png\"%image_prefix ) )\n",
        "\n",
        "  image_arr = []\n",
        "\n",
        "  mask_arr = []\n",
        "\n",
        "  # Loop ... What is index, item? datatype ???\n",
        "  for index,item in enumerate( image_name_arr ):\n",
        "\n",
        "      # Open the image, set as grayscale or NOT\n",
        "      img = io.imread( item, as_gray = image_as_gray )\n",
        "\n",
        "      # Reshape... only if it's image_as_gray == TRUE \n",
        "      img = np.reshape( img,img.shape + (1,) ) if image_as_gray else img\n",
        "\n",
        "      # open mask image ... wtf does replace do?\n",
        "      mask = io.imread( item.replace( image_path,mask_path ).replace( image_prefix,mask_prefix ),as_gray = mask_as_gray )\n",
        "\n",
        "      # Reshape... only if it's mask_as_gray == TRUE \n",
        "      mask = np.reshape( mask,mask.shape + (1,) ) if mask_as_gray else mask\n",
        "\n",
        "      # Call adjustData( ) function \n",
        "      img,mask = adjustData( img, mask, flag_multi_class, num_class )\n",
        "\n",
        "      # append the image, mask to each array         \n",
        "      image_arr.append( img )\n",
        "      mask_arr.append( mask )\n",
        "\n",
        "  image_arr = np.array( image_arr )\n",
        "  mask_arr = np.array( mask_arr )\n",
        "\n",
        "  return image_arr, mask_arr"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CA8WAtl2rXt",
        "colab_type": "text"
      },
      "source": [
        "##### Functions: labelVisiualize & saveResult"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JmHfOQYiYEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What does this do?\n",
        "def labelVisualize( num_class, color_dict, img ):\n",
        "\n",
        "    img = img[ :,:,0 ] if len( img.shape ) == 3 else img\n",
        "\n",
        "    img_out = np.zeros( img.shape + (3,) )\n",
        "\n",
        "    for i in range( num_class ):\n",
        "        img_out[ img == i,: ] = color_dict[ i ]\n",
        "\n",
        "    return img_out / 255\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def saveResult( save_path, npyfile, flag_multi_class = False, num_class = 2 ):\n",
        "  '''\n",
        "  save_path -->\n",
        "  npyfile --> \n",
        "  flag_multi_class --> bool \n",
        "  num_class --> \n",
        "\n",
        "  '''\n",
        "\n",
        "  for i,item in enumerate( npyfile ):\n",
        "\n",
        "      img = labelVisualize( num_class, COLOR_DICT, item ) if flag_multi_class else item[ :,:,0 ]\n",
        "\n",
        "      io.imsave( os.path.join( save_path,\"%d_predict.png\"%i ),img )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq76izoIuHg6",
        "colab_type": "text"
      },
      "source": [
        "## Create the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBSyyRwnjasV",
        "colab_type": "text"
      },
      "source": [
        "### Model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYVEV3mPjm9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "\n",
        "# (874, 1164, 3)\n",
        "def unet( pretrained_weights = None, input_size = ( 874, 1164, 3 ) ):\n",
        "\n",
        "    inputs = Input( input_size )\n",
        "    conv1 = Conv2D( 64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal' )( inputs )\n",
        "    conv1 = Conv2D( 64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal' )( conv1 )\n",
        "    pool1 = MaxPooling2D( pool_size=( 2, 2 ))( conv1 )\n",
        "    conv2 = Conv2D( 128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal' )( pool1 )\n",
        "    conv2 = Conv2D( 128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')( conv2 )\n",
        "    pool2 = MaxPooling2D( pool_size=( 2, 2 ))( conv2 )\n",
        "    conv3 = Conv2D( 256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')( pool2 )\n",
        "    conv3 = Conv2D( 256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')( conv3 )\n",
        "    pool3 = MaxPooling2D( pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D( 512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')( pool3 )\n",
        "    conv4 = Conv2D( 512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')( conv4 )\n",
        "    drop4 = Dropout( 0.5 )( conv4 )\n",
        "    pool4 = MaxPooling2D( pool_size=( 2, 2 ))( drop4 )\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    ## upsampling begins here \n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9) # ???? why is (conv9) here?\n",
        "    \n",
        "\n",
        "    model = Model(input = inputs, output = conv10)\n",
        "    # 'categorical_crossentropy'\n",
        "    # model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    #model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsQvGgxcuTTp",
        "colab_type": "text"
      },
      "source": [
        "## Execute the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTTVkUDVjMHE",
        "colab_type": "text"
      },
      "source": [
        "### Main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DL5cJ2GjGL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "57f5bbc5-3ced-431c-b026-2864df354969"
      },
      "source": [
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "trainDir = '/content/comma10k/train'\n",
        "validDir = '/content/comma10k/valid' \n",
        "\n",
        "# Changes to your images \n",
        "data_gen_args = dict( rotation_range=0.2,\n",
        "                      width_shift_range=0.05,\n",
        "                      height_shift_range=0.05,\n",
        "                      shear_range=0.05,\n",
        "                      zoom_range=0.05,\n",
        "                      horizontal_flip=True,\n",
        "                      fill_mode='nearest')\n",
        "\n",
        "# Create a training generator \n",
        "myGene = trainGenerator( 100, \n",
        "                        trainDir, \n",
        "                        'image', \n",
        "                        'mask', \n",
        "                        data_gen_args, \n",
        "                        save_to_dir = None )\n",
        "\n",
        "print( 'myGene: ', myGene )\n",
        "for i in myGene: \n",
        "  print( i ) \n",
        "\n",
        "model = unet()\n",
        "\n",
        "\n",
        "# Save your model at this checkpoint \n",
        "# MCP( filepath, \n",
        "#      monitor = the value being monitored, e.g., 'loss' \n",
        "#      verbose = 0: shows you nothing, 1: shows animated progress bar, 2: shows # of epochs 1/10  \n",
        "#      save_best_only= If true, then model weights are saved)\n",
        "model_checkpoint = ModelCheckpoint('/content/comma10k/unet_CommaModel.hdf5', \n",
        "                                   monitor = 'loss',\n",
        "                                   verbose = 2, \n",
        "                                   save_best_only = True)\n",
        "\n",
        "\n",
        "model.fit_generator( myGene,\n",
        "                    steps_per_epoch = 300,\n",
        "                    epochs=1,\n",
        "                    callbacks=[ model_checkpoint ])\n",
        "\n",
        "testGene = testGenerator( validDir )\n",
        "\n",
        "results = model.predict_generator( testGene,\n",
        "                                   30,\n",
        "                                   verbose=1 )\n",
        "\n",
        "# Save your results HERE\n",
        "saveResult( validDir,\n",
        "            results )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "myGene:  <generator object trainGenerator at 0x7f8c49074d00>\n",
            "Found 0 images belonging to 1 classes.\n",
            "Found 0 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-60bccb539743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'myGene: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyGene\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyGene\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-6677017262d2>\u001b[0m in \u001b[0;36mtrainGenerator\u001b[0;34m(batch_size, train_path, image_folder, mask_folder, aug_dict, image_color_mode, mask_color_mode, image_save_prefix, mask_save_prefix, flag_multi_class, num_class, save_to_dir, target_size, seed)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjustData\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_multi_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-a16af82cf81a>\u001b[0m in \u001b[0;36madjustData\u001b[0;34m(img, mask, flag_multi_class, num_class)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# ???? What does the following do?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2666\u001b[0m     \"\"\"\n\u001b[1;32m   2667\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2668\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uZ5sjEjmaLJ",
        "colab_type": "text"
      },
      "source": [
        "## Save Model, Save Predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9nfWu0umfQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model, save as a predictor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-At5Iu5DTRt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "7b20193b-f9fc-4532-87df-c00b681fed57"
      },
      "source": [
        "for i in comma10kFolder.iterdir():\n",
        "  print( i )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/comma10k/scale\n",
            "/content/comma10k/viewer.py\n",
            "/content/comma10k/imgs\n",
            "/content/comma10k/pencil\n",
            "/content/comma10k/masks\n",
            "/content/comma10k/.git\n",
            "/content/comma10k/.gitignore\n",
            "/content/comma10k/stat.py\n",
            "/content/comma10k/sample.gif\n",
            "/content/comma10k/.github\n",
            "/content/comma10k/README.md\n",
            "/content/comma10k/sample.jpg\n",
            "/content/comma10k/valid\n",
            "/content/comma10k/LICENSE\n",
            "/content/comma10k/train\n",
            "/content/comma10k/tools\n",
            "/content/comma10k/files_trainable\n",
            "/content/comma10k/requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQOO_EteDh8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}