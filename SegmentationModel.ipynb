{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SegmentationModel.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pFTx1ACYmNi5"
      ],
      "authorship_tag": "ABX9TyNu1uEIsTLynPzqEwuA/Pse",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lvllvl/unet/blob/master/SegmentationModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58UCK5ZVnuwn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFTx1ACYmNi5",
        "colab_type": "text"
      },
      "source": [
        "## Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE5YrFh_tvqK",
        "colab_type": "text"
      },
      "source": [
        "* imgs/  -- The png image files\n",
        "* masks/ -- PNG segmentation masks (update these!)\n",
        "* segs/  -- The outputs in probability from our * * \n",
        "internal segnet (unreleased, too big)\n",
        "\n",
        "\n",
        "\n",
        "###### Categories \n",
        " * 1 - #402020 - road (all parts, anywhere nobody would look at you funny for driving)\n",
        " * 2 - #ff0000 - lane markings (don't include non lane markings like turn arrows and crosswalks)\n",
        " * 3 - #808060 - undrivable\n",
        " * 4 - #00ff66 - movable (vehicles and people/animals)\n",
        " * 5 - #cc00ff - my car (and anything inside it, including wires, mounts, etc. No reflections)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GXS0VBGnukc",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xJ54484gQEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import pathlib\n",
        "from PIL import  Image\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0SXoe8NsDWO",
        "colab_type": "text"
      },
      "source": [
        "#### Import U-Net repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ybe7KSzgNxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "463c1f87-c5fc-4d65-f59c-5d379c9a3fbf"
      },
      "source": [
        "! git clone https://github.com/lvllvl/unet.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'unet'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 418 (delta 6), reused 0 (delta 0), pack-reused 406\u001b[K\n",
            "Receiving objects: 100% (418/418), 44.97 MiB | 35.10 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1MMDxAzsAGR",
        "colab_type": "text"
      },
      "source": [
        "#### import comma10k Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pPSTOzlkikQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "6e20e1a6-0c1f-4380-b83a-5be4ac632eef"
      },
      "source": [
        "! git clone https://github.com/commaai/comma10k.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'comma10k'...\n",
            "remote: Enumerating objects: 27383, done.\u001b[K\n",
            "remote: Total 27383 (delta 0), reused 0 (delta 0), pack-reused 27383\u001b[K\n",
            "Receiving objects: 100% (27383/27383), 3.75 GiB | 42.67 MiB/s, done.\n",
            "Resolving deltas: 100% (4283/4283), done.\n",
            "Checking out files: 100% (11203/11203), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5vihNpcsJaW",
        "colab_type": "text"
      },
      "source": [
        "#### Set up the folders, paths "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-f4N_65gbH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = Path.cwd()\n",
        "\n",
        "# Comma10k data\n",
        "comma10kFolder = path/'comma10k'\n",
        "masksFolder = comma10kFolder/'masks' # Images with the masks ( 5574 images )\n",
        "imgsFolder = comma10kFolder/'imgs' # Images with no segmentation\n",
        "\n",
        "# Unet Path \n",
        "unetFolder = path/'unet'\n",
        "\n",
        "\n",
        "# Create directories for Train / validation datasets \n",
        "validFiles = comma10kFolder/'valid'\n",
        "validFiles.mkdir( mode=511, parents= True, exist_ok = False )\n",
        "\n",
        "trainFiles = comma10kFolder/'train'\n",
        "trainFiles.mkdir( mode=511, parents=True, exist_ok=False )\n",
        "\n",
        "# Training folder --> mask folder --> masks.png\n",
        "# Training folder --> image folder --> image.png\n",
        "trainMask = trainFiles/'mask'\n",
        "trainMask.mkdir( mode=511, parents=True, exist_ok = False )\n",
        "\n",
        "trainImage = trainFiles/'image'\n",
        "trainImage.mkdir( mode=511, parents=True, exist_ok = False )\n",
        "\n",
        "\n",
        "# Valid folder --> mask folder --> masks.png\n",
        "# Valid folder --> image folder --> image.png\n",
        "validMask = validFiles/'mask'\n",
        "validMask.mkdir( mode=511, parents=True, exist_ok = False )\n",
        "\n",
        "validImage = validFiles/'image'\n",
        "validImage.mkdir( mode=511, parents=True, exist_ok = False )\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4wcfmCcaw9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c652e1ff-aced-4188-bf19-6321af3ad882"
      },
      "source": [
        "img = 0\n",
        "for i in imgsFolder.iterdir():\n",
        "  name = i.as_uri()[ 7: ]\n",
        "  print( name )\n",
        "  img = cv2.imread( name )\n",
        "  break \n",
        "img.shape\n",
        "# (874, 1164, 3)\n",
        "# (874, 1164, 3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/comma10k/imgs/0272_55d35794f4955cd1_2018-05-08--18-37-21_13_630.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(874, 1164, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe8gZ8mzn9TD",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nopF6jtoufj",
        "colab_type": "text"
      },
      "source": [
        "#### Rename files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-Aul9z9mc7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "71b2600c-7d0a-4aec-bd21-d6130fa9c394"
      },
      "source": [
        "fileCount = 0\n",
        "prefix = 'mask_'\n",
        "suffix = '.png'\n",
        "\n",
        "for i in masksFolder.iterdir():\n",
        "\n",
        "  file_path = i.as_uri()[ 7:31 ]\n",
        "  \n",
        "  name = i.as_uri()[ 31 : 35 ] \n",
        "\n",
        "  newName = file_path + prefix + name + suffix\n",
        "\n",
        "  i.rename( newName ) # rename the file\n",
        "\n",
        "  # how to evaluate a model in practice \n",
        "  # projects --> github profile, blog, working website \n",
        "  # get good at one specific thing --> e.g., computer vision \n",
        "  \n",
        "  fileCount += 1 \n",
        "\n",
        "  if fileCount % 500 == 0:\n",
        "    print( 'Still processing...file count = ', fileCount )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Still processing...file count =  500\n",
            "Still processing...file count =  1000\n",
            "Still processing...file count =  1500\n",
            "Still processing...file count =  2000\n",
            "Still processing...file count =  2500\n",
            "Still processing...file count =  3000\n",
            "Still processing...file count =  3500\n",
            "Still processing...file count =  4000\n",
            "Still processing...file count =  4500\n",
            "Still processing...file count =  5000\n",
            "Still processing...file count =  5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_PymrffmnFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "b0e7afc6-5059-4125-e853-eceb11cb009c"
      },
      "source": [
        "fileCount = 0\n",
        "prefix = 'image_'\n",
        "suffix = '.png'\n",
        "\n",
        "\n",
        "for i in imgsFolder.iterdir():\n",
        "  \n",
        "  file_path = i.as_uri()[ 7:30 ]\n",
        "  \n",
        "  name = i.as_uri()[ 30 : 34 ] \n",
        "\n",
        "  newName = file_path + prefix + name + suffix\n",
        "\n",
        "  i.rename( newName ) # rename the file\n",
        "  fileCount += 1 \n",
        "\n",
        "  if fileCount % 500 == 0:\n",
        "    print( 'Still processing...file count = ', fileCount )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Still processing...file count =  500\n",
            "Still processing...file count =  1000\n",
            "Still processing...file count =  1500\n",
            "Still processing...file count =  2000\n",
            "Still processing...file count =  2500\n",
            "Still processing...file count =  3000\n",
            "Still processing...file count =  3500\n",
            "Still processing...file count =  4000\n",
            "Still processing...file count =  4500\n",
            "Still processing...file count =  5000\n",
            "Still processing...file count =  5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljw8UxC96JHj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "c1337478-aaca-434b-9ae3-918dc9c7f685"
      },
      "source": [
        "for i in comma10kFolder.iterdir():\n",
        "  print( i )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/comma10k/scale\n",
            "/content/comma10k/viewer.py\n",
            "/content/comma10k/imgs\n",
            "/content/comma10k/pencil\n",
            "/content/comma10k/masks\n",
            "/content/comma10k/.git\n",
            "/content/comma10k/.gitignore\n",
            "/content/comma10k/stat.py\n",
            "/content/comma10k/sample.gif\n",
            "/content/comma10k/.github\n",
            "/content/comma10k/README.md\n",
            "/content/comma10k/sample.jpg\n",
            "/content/comma10k/valid\n",
            "/content/comma10k/LICENSE\n",
            "/content/comma10k/train\n",
            "/content/comma10k/tools\n",
            "/content/comma10k/files_trainable\n",
            "/content/comma10k/requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JdHkmSJ8Zq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8255e61-3c98-49df-cbc6-780b212e01b2"
      },
      "source": [
        "masksFolder.parent"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/comma10k')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZUJhEocEHkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5be404b9-58fb-44c3-b9ea-f02b77b4f79c"
      },
      "source": [
        "mask = 0 \n",
        "img = 0 \n",
        "\n",
        "for i in masksFolder.iterdir():\n",
        "  mask += 1\n",
        "for i in imgsFolder.iterdir():\n",
        "  img += 1\n",
        "\n",
        "print( mask, img )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5574 5574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHtcNBuP2COY",
        "colab_type": "text"
      },
      "source": [
        "#### Split files into train / valid folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wileExm16tkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d7ce2886-1f4f-4ec6-d144-ec184f406a0c"
      },
      "source": [
        "# Masked Files -- Change location \n",
        "\n",
        "fileNames = []\n",
        "count = 0\n",
        "\n",
        "for i in masksFolder.iterdir():\n",
        "\n",
        "  fn = i.stem + i.suffix # file name\n",
        "  # print( 'fn = ', fn ) \n",
        "\n",
        "  if count < 4459:  # add to Train folder \n",
        "    fileNum = i.stem[ 5: ]\n",
        "    fileNames.append( fileNum ) # append FileNum to fileNames array \n",
        "    \n",
        "    # Now change the location \n",
        "    i.rename( Path( trainMask, fn ))\n",
        "\n",
        "  else: # add to Valid folder\n",
        "    i.rename( Path( validFiles, fn ))\n",
        "\n",
        "\n",
        "  count += 1\n",
        "\n",
        "print( 'len of fileNames: ', len( fileNames ))\n",
        "c= 0\n",
        "for i in trainFiles.iterdir():\n",
        "  c += 1\n",
        "print( c )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len of fileNames:  4459\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuazNEMCBnEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b8ad7fb-acc2-4f5f-ca3e-383d42a16551"
      },
      "source": [
        "# Now move the images from the imgsFolder \n",
        "for i in imgsFolder.iterdir():\n",
        "\n",
        "  fn = i.stem + i.suffix # individual file name \n",
        "  \n",
        "  fileNum = i.stem[ 6: ]\n",
        "\n",
        "  if fileNum in fileNames: # change location - train folder if fileNum is in array fileNames\n",
        "    i.rename( Path( trainImage, fn ))\n",
        "\n",
        "  else: # change location  - valid folder \n",
        "    i.rename( Path( validFiles, fn ))\n",
        "\n",
        "c = 0\n",
        "for i in trainFiles.iterdir():\n",
        "  c += 1 \n",
        "print( c ) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz8Eg-ltjBAb",
        "colab_type": "text"
      },
      "source": [
        "### Data.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUuOjm9c1G81",
        "colab_type": "text"
      },
      "source": [
        "##### Imports, etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGD1vz_v09qG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np \n",
        "import os\n",
        "import glob\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "\n",
        "# CommaAI Labels --> 5 classes\n",
        "road = [ 64,\t32,\t32 ] \n",
        "lane_markings = [ 255, 0, 0 ] \n",
        "undriveable = [ 128, 128, 96 ] \n",
        "movable = [ 0, 255, 102 ] # vehicles, peoples, animals \n",
        "my_vehicle = [ 204,\t0, 255 ]\n",
        "\n",
        "# What does this do?\n",
        "COLOR_DICT = np.array( [ road, lane_markings, undriveable, movable, my_vehicle ])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZYwo7IA1Kgc",
        "colab_type": "text"
      },
      "source": [
        "##### Function: adjustData"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quk4M9O-1P34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjustData( img, mask, flag_multi_class, num_class ):\n",
        "\n",
        "    if( flag_multi_class ):\n",
        "\n",
        "        img = img / 255 \n",
        "        mask = mask[ :,:,:,0 ] if( len( mask.shape ) == 4 ) else mask[ :,:,0 ]\n",
        "        new_mask = np.zeros( mask.shape + ( num_class, ) )\n",
        "\n",
        "        for i in range( num_class ):\n",
        "\n",
        "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
        "            #index = np.where(mask == i)\n",
        "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
        "            #new_mask[index_mask] = 1\n",
        "            new_mask[ mask == i,i ] = 1\n",
        "\n",
        "        new_mask = np.reshape( new_mask,( new_mask.shape[ 0 ],new_mask.shape[ 1 ]*new_mask.shape[ 2 ],new_mask.shape[ 3 ] )) if flag_multi_class else np.reshape( new_mask,( new_mask.shape[ 0 ] * new_mask.shape[ 1 ],new_mask.shape[ 2 ]))\n",
        "        mask = new_mask\n",
        "        \n",
        "        # TODO: delete this \n",
        "        print( 'adjustData: mask.shape --> ' , mask.shape ) \n",
        "\n",
        "    elif ( np.max( img ) > 1 ): # if the max value in img is greater than 1\n",
        "\n",
        "        # make every number img[ i ] 0 <= i <= 1\n",
        "        img = img / 255\n",
        "        mask = mask / 255\n",
        "        mask[ mask > 0.5 ] = 1\n",
        "        mask[ mask <= 0.5 ] = 0\n",
        "\n",
        "    return ( img,mask )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDP5UPH71U2n",
        "colab_type": "text"
      },
      "source": [
        "##### Function: trainGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvGcSDJ_1cMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainGenerator( batch_size, train_path, image_folder, mask_folder, aug_dict, image_color_mode = \"rgb\",\n",
        "                    mask_color_mode = \"rgb\", image_save_prefix  = \"image\", mask_save_prefix  = \"mask\",\n",
        "                    flag_multi_class = True, num_class = 5, save_to_dir = None, target_size = ( 256,256 ), seed = 1 ):\n",
        "    '''\n",
        "    can generate image and mask at the same time\n",
        "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
        "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "    '''\n",
        "    image_datagen = ImageDataGenerator( **aug_dict )\n",
        "    # TODO delete this \n",
        "    print( 'image_datagen type : ', type( image_datagen ) )\n",
        "\n",
        "    mask_datagen = ImageDataGenerator( **aug_dict )\n",
        "    # TODO delete this \n",
        "    print( 'mask_datagen type : ', type( mask_datagen ) )\n",
        "\n",
        "\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [ image_folder ],\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = image_save_prefix,\n",
        "        seed = seed )\n",
        "    \n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [ mask_folder ],\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = mask_save_prefix,\n",
        "        seed = seed )\n",
        "    \n",
        "    train_generator = zip( image_generator, mask_generator )\n",
        "\n",
        "    for ( img, mask ) in train_generator:\n",
        "\n",
        "        img, mask = adjustData( img, mask, flag_multi_class, num_class )\n",
        "        yield ( img, mask )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv-jWANw1hc9",
        "colab_type": "text"
      },
      "source": [
        "##### Function: testGenerator "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1X4RHv31l5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testGenerator( test_path, num_image = 30, target_size = ( 256,256 ), flag_multi_class = True, as_gray = False ):\n",
        "  '''\n",
        "      num_image -->> ??? What does this do ? total number of images in your test dataset????\n",
        "      target_size = ( ?, ? ) what should this actually be?\n",
        "  '''\n",
        "  for i in range( num_image ): # do the following for all images in test dataset\n",
        "\n",
        "      img = io.imread( os.path.join( test_path,\"%d.png\"%i ), as_gray = as_gray )\n",
        "\n",
        "      img = img / 255\n",
        "\n",
        "      img = trans.resize( img,target_size )\n",
        "\n",
        "      img = np.reshape( img, img.shape+(1,) ) if ( not flag_multi_class ) else img\n",
        "\n",
        "      img = np.reshape( img, (1,) + img.shape )\n",
        "\n",
        "      yield img"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKzr0DxB10pF",
        "colab_type": "text"
      },
      "source": [
        "##### Function: geneTrainNpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvdfkutq14S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def geneTrainNpy( image_path, mask_path, flag_multi_class = True, num_class = 5,\n",
        "                 image_prefix = \"image\", mask_prefix = \"mask\", image_as_gray = False, mask_as_gray = False ):\n",
        "  '''\n",
        "  image_path -> path to image\n",
        "  mask_path -> path to image\n",
        "\n",
        "  flag_multi_class = T/F --> Are there multiple classes or not?\n",
        "  num_class = # His is set to 2, because it's black & white \n",
        "\n",
        "  image_prefix --> how is filename labeled?\n",
        "  mask_prefix --> how is filename labeled?\n",
        "\n",
        "  image_as_gray --> T / F --> is the image gray or not\n",
        "  mask_as_gray --> T / F --> is MASK gray or not  \n",
        "\n",
        "  '''\n",
        "    # Access image path\n",
        "  image_name_arr = glob.glob( os.path.join( image_path,\"%s*.png\"%image_prefix ) )\n",
        "\n",
        "  image_arr = []\n",
        "\n",
        "  mask_arr = []\n",
        "\n",
        "  # Loop ... What is index, item? datatype ???\n",
        "  for index,item in enumerate( image_name_arr ):\n",
        "\n",
        "      # Open the image, set as grayscale or NOT\n",
        "      img = io.imread( item, as_gray = image_as_gray )\n",
        "\n",
        "      # Reshape... only if it's image_as_gray == TRUE \n",
        "      img = np.reshape( img,img.shape + (1,) ) if image_as_gray else img\n",
        "\n",
        "      # open mask image ... wtf does replace do?\n",
        "      mask = io.imread( item.replace( image_path,mask_path ).replace( image_prefix,mask_prefix ),as_gray = mask_as_gray )\n",
        "\n",
        "      # Reshape... only if it's mask_as_gray == TRUE \n",
        "      mask = np.reshape( mask,mask.shape + (1,) ) if mask_as_gray else mask\n",
        "\n",
        "      # Call adjustData( ) function \n",
        "      img,mask = adjustData( img, mask, flag_multi_class, num_class )\n",
        "\n",
        "      # append the image, mask to each array         \n",
        "      image_arr.append( img )\n",
        "      mask_arr.append( mask )\n",
        "\n",
        "  image_arr = np.array( image_arr )\n",
        "  mask_arr = np.array( mask_arr )\n",
        "\n",
        "  return image_arr, mask_arr"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CA8WAtl2rXt",
        "colab_type": "text"
      },
      "source": [
        "##### Functions: labelVisiualize & saveResult"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JmHfOQYiYEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What does this do?\n",
        "def labelVisualize( num_class, color_dict, img ):\n",
        "\n",
        "    img = img[ :,:,0 ] if len( img.shape ) == 3 else img\n",
        "\n",
        "    img_out = np.zeros( img.shape + (3,) )\n",
        "\n",
        "    for i in range( num_class ):\n",
        "        img_out[ img == i,: ] = color_dict[ i ]\n",
        "\n",
        "    return img_out / 255\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def saveResult( save_path, npyfile, flag_multi_class = False, num_class = 2 ):\n",
        "  '''\n",
        "  save_path -->\n",
        "  npyfile --> \n",
        "  flag_multi_class --> bool \n",
        "  num_class --> \n",
        "\n",
        "  '''\n",
        "\n",
        "  for i,item in enumerate( npyfile ):\n",
        "\n",
        "      img = labelVisualize( num_class, COLOR_DICT, item ) if flag_multi_class else item[ :,:,0 ]\n",
        "\n",
        "      io.imsave( os.path.join( save_path,\"%d_predict.png\"%i ),img )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq76izoIuHg6",
        "colab_type": "text"
      },
      "source": [
        "## Create the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBSyyRwnjasV",
        "colab_type": "text"
      },
      "source": [
        "### Model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYVEV3mPjm9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "\n",
        "# (874, 1164, 3)\n",
        "def unet( pretrained_weights = None, input_size = ( 256, 256 ) ):\n",
        "\n",
        "    inputs = Input( input_size )\n",
        "    conv1 = Conv2D( 64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal' )( inputs )\n",
        "    conv1 = Conv2D( 64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal' )( conv1 )\n",
        "    pool1 = MaxPooling2D( pool_size=( 2, 2 ))( conv1 )\n",
        "    conv2 = Conv2D( 128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal' )( pool1 )\n",
        "    conv2 = Conv2D( 128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')( conv2 )\n",
        "    pool2 = MaxPooling2D( pool_size=( 2, 2 ))( conv2 )\n",
        "    conv3 = Conv2D( 256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')( pool2 )\n",
        "    conv3 = Conv2D( 256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')( conv3 )\n",
        "    pool3 = MaxPooling2D( pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D( 512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')( pool3 )\n",
        "    conv4 = Conv2D( 512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')( conv4 )\n",
        "    drop4 = Dropout( 0.5 )( conv4 )\n",
        "    pool4 = MaxPooling2D( pool_size=( 2, 2 ))( drop4 )\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    ## upsampling begins here \n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9) # ???? why is (conv9) here?\n",
        "    \n",
        "\n",
        "    model = Model(input = inputs, output = conv10)\n",
        "    # 'categorical_crossentropy'\n",
        "    # model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    #model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsQvGgxcuTTp",
        "colab_type": "text"
      },
      "source": [
        "## Execute the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTTVkUDVjMHE",
        "colab_type": "text"
      },
      "source": [
        "### Main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DL5cJ2GjGL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "21fa2392-82e4-448c-ffdd-b227f6fc117b"
      },
      "source": [
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "trainDir = '/content/comma10k/train'\n",
        "validDir = '/content/comma10k/valid' \n",
        "\n",
        "# Changes to your images \n",
        "data_gen_args = dict( rotation_range=0.2,\n",
        "                      width_shift_range=0.05,\n",
        "                      height_shift_range=0.05,\n",
        "                      shear_range=0.05,\n",
        "                      zoom_range=0.05,\n",
        "                      horizontal_flip=True,\n",
        "                      fill_mode='nearest')\n",
        "\n",
        "# Create a training generator \n",
        "myGene = trainGenerator( 100, \n",
        "                        trainDir, \n",
        "                        'image', \n",
        "                        'mask', \n",
        "                        data_gen_args, \n",
        "                        save_to_dir = None )\n",
        "\n",
        "\n",
        "# model = unet( pretrained_weights=None, input_size= ( 256, 256, 3 ))\n",
        "model = unet()\n",
        "\n",
        "\n",
        "# Save your model at this checkpoint \n",
        "# MCP( filepath, \n",
        "#      monitor = the value being monitored, e.g., 'loss' \n",
        "#      verbose = 0: shows you nothing, 1: shows animated progress bar, 2: shows # of epochs 1/10  \n",
        "#      save_best_only= If true, then model weights are saved)\n",
        "model_checkpoint = ModelCheckpoint('content/comma10k/unet_CommaModel.hdf5', \n",
        "                                   monitor = 'loss',\n",
        "                                   verbose = 2, \n",
        "                                   save_best_only = True)\n",
        "\n",
        "\n",
        "model.fit_generator( myGene,\n",
        "                    steps_per_epoch = 300,\n",
        "                    epochs=1,\n",
        "                    callbacks=[ model_checkpoint ])\n",
        "\n",
        "testGene = testGenerator( validDir )\n",
        "\n",
        "results = model.predict_generator( testGene,\n",
        "                                   30,\n",
        "                                   verbose=1 )\n",
        "\n",
        "# Save your results HERE\n",
        "saveResult( validDir,\n",
        "            results )"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-23b9bf2438a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# model = unet( pretrained_weights=None, input_size= ( 256, 256, 3 ))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-7b8fd1667fd6>\u001b[0m in \u001b[0;36munet\u001b[0;34m(pretrained_weights, input_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'he_normal'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'he_normal'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mconv1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mconv1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1090\u001b[0m       \u001b[0;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    194\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: [None, 256, 256]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uZ5sjEjmaLJ",
        "colab_type": "text"
      },
      "source": [
        "## Save Model, Save Predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9nfWu0umfQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model, save as a predictor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-At5Iu5DTRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in comma10kFolder.iterdir():\n",
        "  print( i )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQOO_EteDh8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}